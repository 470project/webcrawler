{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import scrapy\n",
    "except:\n",
    "    !pip install scrapy\n",
    "    import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from twisted.internet import reactor\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerRunner\n",
    "from scrapy.utils.log import configure_logging\n",
    "import json\n",
    "\n",
    "class JsonWriterPipeline(object):\n",
    "\n",
    "    def open_spider(self, spider):\n",
    "        self.file = open('quoteresult.jl', 'w')\n",
    "\n",
    "    def close_spider(self, spider):\n",
    "        self.file.close()\n",
    "\n",
    "    def process_item(self, item, spider):\n",
    "        line = json.dumps(dict(item)) + \"\\n\"\n",
    "        self.file.write(line)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('harryPotterCharacters.json') as f:\n",
    "    characters = [x.lower() for x in json.load(f)[\"characters\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from dateutil import parser\n",
    "\n",
    "def isUserLink(href):\n",
    "    m = re.match('/u/\\d+/\\w+', href)\n",
    "    if(m is None):\n",
    "        return False\n",
    "    return True\n",
    "def isStoryLink(href):\n",
    "    m = re.match('.*(?P<link>/s/\\d+(/\\d+)?/.*)', href)\n",
    "    if(m is None):\n",
    "        return False\n",
    "    return True\n",
    "def extractStoryLink(href):\n",
    "    m = re.match('.*(?P<link>/s/\\d+(/\\d+)?/.*)', href)\n",
    "    if(m is None):\n",
    "        return \"\"\n",
    "    return m.group('link')\n",
    "def isReviewLink(href):\n",
    "    m = re.match('/r/\\d+', href)\n",
    "    if(m is None):\n",
    "        return False\n",
    "    return True\n",
    "def convertDate(strDate):\n",
    "    now = datetime.now()\n",
    "    mSeconds = re.match('(?P<seconds>\\d+)s', strDate)\n",
    "    mMinutes = re.match('(?P<minutes>\\d+)m', strDate)\n",
    "    mHours = re.match('(?P<hours>\\d+)h', strDate)\n",
    "    \n",
    "    mDate = re.match('(?P<month>\\w{3}) (?P<day>\\d+)(, (?P<year>\\d{4}))?', strDate)\n",
    "    delta = timedelta(0)\n",
    "    if(mSeconds is not None):\n",
    "        delta = timedelta(0,int(mSeconds.group('seconds')))\n",
    "    if(mMinutes is not None):\n",
    "        delta = timedelta(minutes = int(mMinutes.group('minutes')))  \n",
    "    if(mHours is not None):\n",
    "        delta = timedelta(hours = int(mHours.group('hours'))) \n",
    "    if(mDate is not None):\n",
    "        return parser.parse(strDate)\n",
    "    return now + delta\n",
    "\n",
    "def getOtherInfoAsJson(other_stuff):\n",
    "    language = ''\n",
    "    genre = ''\n",
    "    favorites = 0\n",
    "    follows = 0\n",
    "    reviews = 0\n",
    "    words = -1\n",
    "    chapters = 1\n",
    "    language_genre_match = re.search(\n",
    "            '(?P<language>\\w+) - ((?P<genre1>\\w+)/(?P<genre2>\\w+))', \n",
    "            other_stuff)\n",
    "    if(language_genre_match is not None):\n",
    "        language = language_genre_match.group('language')\n",
    "        genre = [language_genre_match.group('genre1'), language_genre_match.group('genre2')]\n",
    "    \n",
    "    mReviews = re.search(\n",
    "            'Reviews: <a.*>(?P<reviews>\\d+)</a>', \n",
    "            other_stuff)\n",
    "    if(mReviews is not None):\n",
    "        reviews = mReviews.group('reviews')\n",
    "        \n",
    "    mWords = re.search(\n",
    "            'Words: (?P<words>(\\d+,?)+)', \n",
    "            other_stuff)\n",
    "    if(mWords is not None):\n",
    "        words = mWords.group('words')\n",
    "    \n",
    "    mChapters = re.search(\n",
    "            'Chapters: (?P<chapters>(\\d+,?)+)', \n",
    "            other_stuff)\n",
    "    if(mChapters is not None):\n",
    "        chapters = mChapters.group('chapters')\n",
    "    \n",
    "    mFavorites = re.search(\n",
    "            'Favs: (?P<favorites>\\d+)', \n",
    "            other_stuff)\n",
    "    if(mFavorites is not None):\n",
    "        favorites = mFavorites.group('favorites')\n",
    "\n",
    "    mFollows = re.search(\n",
    "            'Follows: (?P<follows>\\d+)', \n",
    "            other_stuff)\n",
    "    if(mFollows is not None):\n",
    "        follows = mFollows.group('follows')\n",
    "        \n",
    "    return {\n",
    "                'language':language,\n",
    "                'genre': genre,\n",
    "                'favorites': favorites,\n",
    "                'follows': follows,\n",
    "                'reviews': reviews,\n",
    "                'words': words,\n",
    "                'chapters': chapters\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryanc\\Anaconda3\\envs\\cs470\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n",
      "INFO: Overridden settings: {'FEED_FORMAT': 'json', 'FEED_URI': 'fanficResult.json', 'LOG_LEVEL': 30}\n",
      "2018-10-16 14:43:15 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in https://www.fanfiction.net/u/1465660/Ravenclaw-Slytherin. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import string\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "class FanFicSpider(scrapy.Spider):\n",
    "    name = \"fanFic\"\n",
    "    start_urls = [\n",
    "        'https://www.fanfiction.net/s/13025005/1/A-Twist-In-Time'\n",
    "        #'https://www.fanfiction.net/s/13090372/1/This-Labyrinth-of-Suffering'\n",
    "        #'https://www.fanfiction.net/s/13059900/1/La-For%C3%AAt-des-%C3%82mes-Bris%C3%A9es',\n",
    "        #'https://www.fanfiction.net/r/8636004/'\n",
    "    ]\n",
    "    custom_settings = {\n",
    "        'LOG_LEVEL': logging.WARNING,\n",
    "        'ITEM_PIPELINES': {'__main__.JsonWriterPipeline': 1}, # Used for pipeline 1\n",
    "        'FEED_FORMAT':'json',                                 # Used for pipeline 2\n",
    "        'FEED_URI': 'fanficResult.json'                        # Used for pipeline 2\n",
    "    }\n",
    "       \n",
    "    def parseUserPage(self, response):\n",
    "        profile_top = response.xpath('//div[@id=\"content_wrapper_inner\"]')\n",
    "        \n",
    "        #follow links to their stories and reviews\n",
    "        for elem in response.xpath('//div[@class=\"z-list mystories\"]').xpath(\".//@href\"):\n",
    "            if(isStoryLink(elem.extract())):\n",
    "                yield response.follow(elem.extract(), callback=self.parse)\n",
    "                \n",
    "            if(isReviewLink(elem.extract())):\n",
    "                yield response.follow(elem.extract(), callback=self.parseReview)\n",
    "        \n",
    "        #get the favorites\n",
    "        favorites = []\n",
    "        for elem in response.xpath('//div[@class=\"z-list favstories\"]'):\n",
    "            favStory = '';\n",
    "            favAuthor = ''\n",
    "            for link in elem.xpath('./a//@href').extract():\n",
    "                if(isUserLink(link)):\n",
    "                    favAuthor = link\n",
    "                    yield response.follow(link, callback=self.parseUserPage)\n",
    "                elif(isStoryLink(link)):\n",
    "                    favStory = link\n",
    "                    yield response.follow(link, callback=self.parse)\n",
    "                elif(isReviewLink(link)):\n",
    "                    yield response.follow(link, callback=self.parseReview)\n",
    "            favorites.append({\n",
    "                'favStory' : favStory,\n",
    "                'favAuthor': favAuthor\n",
    "            })\n",
    "        \n",
    "        yield {\n",
    "            'pageType': 'user',\n",
    "            'name': profile_top.xpath('.//span/text()').extract_first(),\n",
    "            'favorites': favorites\n",
    "        }\n",
    "        \n",
    "    def parse(self, response):\n",
    "        profile_top = response.xpath('//div[@id=\"profile_top\"]')\n",
    "        storyName = response.xpath('//link[@rel=\"canonical\"]//@href').extract_first()\n",
    "        storyName = extractStoryLink(storyName)\n",
    "        \n",
    "        abstract = (profile_top.xpath('.//div/text()').extract_first())\n",
    "        rating = profile_top.xpath('.//span/a/text()').extract_first()\n",
    "        otherInfo = profile_top.xpath('.//span').extract()[3]\n",
    "        \n",
    "        date = convertDate(profile_top.xpath('.//span/text()').extract()[3])\n",
    "        storyType = response.xpath('//div[@id=\"pre_story_links\"]').xpath('.//a/@href').extract()[-1]\n",
    "        text = response.xpath('//div[@id=\"storytext\"]').extract_first().lower()\n",
    "        \n",
    "        #find relevant characters\n",
    "        characterFreq = {}\n",
    "        for character in characters:\n",
    "            if(character in text):\n",
    "                if(character not in characterFreq):\n",
    "                    characterFreq[character] = 0\n",
    "                characterFreq[character] += text.count(character)\n",
    "          \n",
    "        #get author\n",
    "        author = ''\n",
    "        for link in profile_top.xpath('.//@href'):\n",
    "            if(isUserLink(link.extract())):\n",
    "                author = link.extract()\n",
    "                yield response.follow(author, callback=self.parseUserPage)\n",
    "        \n",
    "        yield {\n",
    "            'pageType': 'story',\n",
    "            'storyLink': storyName,\n",
    "            'author': author,\n",
    "            'title': response.xpath('//title/text()').extract_first(),\n",
    "            'storyType': storyType,\n",
    "            'abstract': abstract,\n",
    "            'rating': rating,\n",
    "            'otherInfo': getOtherInfoAsJson(otherInfo),\n",
    "            'date': date.strftime('%Y-%m-%d %M:%S'),\n",
    "            'characters': characterFreq\n",
    "        }\n",
    "\n",
    "    def parseReview(self, response):\n",
    "        reviewOf = response.xpath('//th').xpath('.//@href').extract_first()\n",
    "        for review in response.xpath('//table[@id=\"gui_table1i\"]//td'):\n",
    "            reviewBody = (review.xpath('.//div/text()').extract_first())\n",
    "            #remove punctuation\n",
    "            table = str.maketrans(\"\", \"\", string.punctuation)\n",
    "            reviewBody = reviewBody.translate(table)\n",
    "            sentimentScore = sum([sid.polarity_scores(word)['compound'] for word in reviewBody.split()])\n",
    "            reviewer = (review.xpath('./text()').extract_first())\n",
    "            if(reviewer is ' '):\n",
    "                reviewer = (review.xpath('./a/@href').extract_first())\n",
    "                yield response.follow(reviewer, callback=self.parseUserPage)\n",
    "            yield{\n",
    "                'pageType': 'review',\n",
    "                'reviewOf': reviewOf,\n",
    "                'reviewer': reviewer,\n",
    "                'reviewBody': reviewBody,\n",
    "                'sentimentScore': sentimentScore\n",
    "            }\n",
    "            \n",
    "from crochet import setup\n",
    "setup()\n",
    "configure_logging({'LOG_FORMAT': '%(levelname)s: %(message)s'})\n",
    "def run_spider():\n",
    "    runner = CrawlerRunner()\n",
    "    d = runner.crawl(FanFicSpider)\n",
    "\n",
    "run_spider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span class=\"xgray xcontrast_txt\">Rated: <a class=\"xcontrast_txt\" href=\"https://www.fictionratings.com/\" target=\"rating\">Fiction  T</a> - English - Mystery/Adventure - Chapters: 13   - Words: 1,123,123,40,782 - Reviews: <a href=\"/r/13025005/\">82</a> - Favs: 13 - Follows: 19 - Updated: <span data-xutime=\"1539713210\">53m</span> - Published: <span data-xutime=\"1533456146\">8/5</span> - id: 13025005 </span>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'language': 'English',\n",
       " 'genre': ['Mystery', 'Adventure'],\n",
       " 'favorites': '13',\n",
       " 'follows': '19',\n",
       " 'reviews': '82',\n",
       " 'words': '1,123,123,40,782',\n",
       " 'chapters': '13'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
