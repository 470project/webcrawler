{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import scrapy\n",
    "except:\n",
    "    !pip install scrapy\n",
    "    import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from twisted.internet import reactor\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerRunner\n",
    "from scrapy.utils.log import configure_logging\n",
    "import json\n",
    "\n",
    "class JsonWriterPipeline(object):\n",
    "\n",
    "    def open_spider(self, spider):\n",
    "        self.file = open('quoteresult.jl', 'w')\n",
    "\n",
    "    def close_spider(self, spider):\n",
    "        self.file.close()\n",
    "\n",
    "    def process_item(self, item, spider):\n",
    "        line = json.dumps(dict(item)) + \"\\n\"\n",
    "        self.file.write(line)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from dateutil import parser\n",
    "\n",
    "def isUserLink(href):\n",
    "    m = re.match('/u/\\d+/\\w+', href)\n",
    "    if(m is None):\n",
    "        return False\n",
    "    return True\n",
    "def isStoryLink(href):\n",
    "    m = re.match('/s/\\d+/\\w+', href)\n",
    "    if(m is None):\n",
    "        return False\n",
    "    return True\n",
    "def isReviewLink(href):\n",
    "    m = re.match('/r/\\d+', href)\n",
    "    if(m is None):\n",
    "        return False\n",
    "    return True\n",
    "def convertDate(strDate):\n",
    "    now = datetime.now()\n",
    "    mSeconds = re.match('(?P<seconds>\\d+)s', strDate)\n",
    "    mMinutes = re.match('(?P<minutes>\\d+)m', strDate)\n",
    "    mHours = re.match('(?P<hours>\\d+)h', strDate)\n",
    "    \n",
    "    mDate = re.match('(?P<month>\\w{3}) (?P<day>\\d+)(, (?P<year>\\d{4}))?', strDate)\n",
    "    delta = timedelta(0)\n",
    "    if(mSeconds is not None):\n",
    "        delta = timedelta(0,int(mSeconds.group('seconds')))\n",
    "    if(mMinutes is not None):\n",
    "        delta = timedelta(minutes = int(mMinutes.group('minutes')))  \n",
    "    if(mHours is not None):\n",
    "        delta = timedelta(hours = int(mHours.group('hours'))) \n",
    "    if(mDate is not None):\n",
    "        return parser.parse(strDate)\n",
    "    return now + delta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Overridden settings: {'FEED_FORMAT': 'json', 'FEED_URI': 'fanficResult.json', 'LOG_LEVEL': 30}\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "class FanFicSpider(scrapy.Spider):\n",
    "    name = \"fanFic\"\n",
    "    start_urls = [\n",
    "        'https://www.fanfiction.net/s/13090372/1/This-Labyrinth-of-Suffering'\n",
    "        #'https://www.fanfiction.net/s/13059900/1/La-For%C3%AAt-des-%C3%82mes-Bris%C3%A9es',\n",
    "        #'https://www.fanfiction.net/r/8636004/'\n",
    "    ]\n",
    "    custom_settings = {\n",
    "        'LOG_LEVEL': logging.WARNING,\n",
    "        'ITEM_PIPELINES': {'__main__.JsonWriterPipeline': 1}, # Used for pipeline 1\n",
    "        'FEED_FORMAT':'json',                                 # Used for pipeline 2\n",
    "        'FEED_URI': 'fanficResult.json'                        # Used for pipeline 2\n",
    "    }\n",
    "    \n",
    "    \n",
    "        \n",
    "    def parseReview(self, response):\n",
    "        reviewOf = response.xpath('//th').xpath('.//@href').extract_first()\n",
    "        #print(response.xpath('//table[@id=\"gui_table1i\"]//td').extract())\n",
    "        for review in response.xpath('//table[@id=\"gui_table1i\"]//td'):\n",
    "            reviewBody = (review.xpath('.//div/text()').extract_first())\n",
    "            reviewer = (review.xpath('./text()').extract_first())\n",
    "            if(reviewer is ' '):\n",
    "                reviewer = (review.xpath('./a/@href').extract_first())\n",
    "                yield response.follow(reviewer, callback=self.parseUserPage)\n",
    "            yield{\n",
    "                'pageType': 'review',\n",
    "                'reviewOf': reviewOf,\n",
    "                'reviewer': reviewer,\n",
    "                'reviewBody': reviewBody\n",
    "            }\n",
    "        \n",
    "    def parseUserPage(self, response):\n",
    "        profile_top = response.xpath('//div[@id=\"content_wrapper_inner\"]')\n",
    "        #print(response.xpath('//div[@class=\"z-list mystories\"]').xpath(\".//@href\"))\n",
    "        cnt = 0\n",
    "        for elem in response.xpath('//div[@class=\"z-list mystories\"]').xpath(\".//@href\"):\n",
    "            if(isStoryLink(elem.extract())):\n",
    "                yield response.follow(elem.extract(), callback=self.parse)\n",
    "            #print(elem.extract())\n",
    "            if(isReviewLink(elem.extract())):\n",
    "                yield response.follow(elem.extract(), callback=self.parseReview)\n",
    "        favorites = []\n",
    "        for elem in response.xpath('//div[@class=\"z-list favstories\"]'):\n",
    "            favStory = '';\n",
    "            favAuthor = ''\n",
    "            for link in elem.xpath('./a//@href').extract():\n",
    "                if(isUserLink(link)):\n",
    "                    favAuthor = link\n",
    "                    yield response.follow(link, callback=self.parseUserPage)\n",
    "                elif(isStoryLink(link)):\n",
    "                    favStory = link\n",
    "                    yield response.follow(link, callback=self.parse)\n",
    "                elif(isReviewLink(link)):\n",
    "                    yield response.follow(link, callback=self.parseReview)\n",
    "            favorites.append({\n",
    "                'favStory' : favStory,\n",
    "                'favAuthor': favAuthor\n",
    "            })\n",
    "        #print(favorites)\n",
    "        yield {\n",
    "            'pageType': 'user',\n",
    "            'name': profile_top.xpath('.//span/text()').extract_first(),\n",
    "            'favorites': favorites\n",
    "        }\n",
    "    def parse(self, response):\n",
    "        profile_top = response.xpath('//div[@id=\"profile_top\"]')\n",
    "        \n",
    "        abstract = (profile_top.xpath('.//div/text()').extract_first())\n",
    "        rating = profile_top.xpath('.//span/a/text()').extract_first()\n",
    "        otherInfo = profile_top.xpath('.//span/text()').extract()[2]\n",
    "        date = convertDate(profile_top.xpath('.//span/text()').extract()[3])\n",
    "        storyType = response.xpath('//div[@id=\"pre_story_links\"]').xpath('.//a/@href').extract()[-1]\n",
    "        author = ''\n",
    "        #get author\n",
    "        for link in profile_top.xpath('.//@href'):\n",
    "            if(isUserLink(link.extract())):\n",
    "                author = link.extract()\n",
    "                #yield response.follow(author, callback=self.parseUserPage)\n",
    "        \n",
    "        yield {\n",
    "            'pageType': 'story',\n",
    "            'author': author,\n",
    "            'title': response.xpath('//title/text()').extract_first(),\n",
    "            'storyType': storyType,\n",
    "            'abstract': abstract,\n",
    "            'rating': rating,\n",
    "            'otherInfo': otherInfo,\n",
    "            'date': date.strftime('%Y-%m-%d %M:%S')\n",
    "        }\n",
    "from crochet import setup\n",
    "setup()\n",
    "configure_logging({'LOG_FORMAT': '%(levelname)s: %(message)s'})\n",
    "def run_spider():\n",
    "    runner = CrawlerRunner()\n",
    "    d = runner.crawl(FanFicSpider)\n",
    "\n",
    "run_spider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Overridden settings: {'FEED_FORMAT': 'json', 'FEED_URI': 'fanficResult.json', 'LOG_LEVEL': 30}\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
